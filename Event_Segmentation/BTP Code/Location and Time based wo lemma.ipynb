{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "import requests\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "lexicon = Empath()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"next_day\", \"Sunday_morning\", \"next_morning\", \"the_next_day\", \"9_am\", \"9am\", \"6am\", \"Friday_morning\", \"next_day\", \"Saturday_morning\", \"Sunday_night\", \"five_o'clock\", \"5_o'clock\", \"8am\", \"following\", \"usual_time\", \"6_am\", \"nine_o'clock\", \"7am\", \"three_o'clock\", \"morning-\", \"8_am\", \"Sunday_night\", \"sunday\", \"five_in_the_morning\", \"8_o'clock\", \"earliest\", \"early_morning\", \"8:00_am\", \"normal_time\", \"Tuesday_morning\", \"around_noon\", \"5am\", \"7:00_pm\", \"Saturday\", \"6_in_the_morning\", \"Saturday\", \"6am\", \"6:00_am\", \"Monday_morning\", \"Sunday_morning\", \"3pm\", \"5_am\", \"around_three\", \"only_day\", \"saturday\", \"10am\", \"day-\", \"6_a.m.\", \"4:00\", \"6:00_in_the_morning\", \"4pm\", \"six_in_the_morning\", \"four_o'clock\", \"11_o'clock\", \"Thursday_morning\", \"2:00\", \"Sunday\", \"Monday_night\", \"ten_o'clock\", \"4_am\", \"Thursday\", \"Wednesday_night\", \"6_o'clock\", \"sunday\", \"4_o'clock\", \"10am\", \"the_morning\", \"9:00\", \"3:00_am\", \"11:30\", \"seven_in_the_morning\", \"10_am\", \"8_in_the_morning\", \"the_day_after\", \"12:00\", \"morning\", \"Friday_afternoon\", \"8:00am\", \"Tuesday_night\", \"7_in_the_morning\", \"5:00\", \"5:00_pm\", \"one_morning\", \"afternoon\", \"10_o'clock\", \"9pm\", \"9_in_the_morning\", \"Tuesday\", \"9_o'clock\", \"six_thirty\", \"5_in_the_morning\", \"same_routine\", \"4am\", \"7:00am\", \"thursday\", \"seven_o'clock\", \"monday\", \"eleven_thirty\", \"Thursday_night\", \"Next_day\", \"Monday\", \"Saturday_afternoon\", \"7:00_am\", \"1pm\", \"5pm\", \"10:00_pm\", \"Friday\", \"2:00_am\", \"4_in_the_morning\", \"7_am\", \"6:30am\", \"six_o'clock\", \"saturday\", \"1:30\", \"around_eight\", \"Wednesday\", \"nights\", \"5:30\", \"10_a.m.\", \"wednesday\", \"eight_o'clock\", \"10pm\", \"next_night\", \"about_noon\", \"Friday\", \"10:00\", \"3_am\", \"friday\", \"noon\", \"4_pm\", \"last_Friday\", \"New_Year's_Eve\", \"Christmas_eve\", \"three_in_the_afternoon\", \"5:00_am\", \"3pm\", \"11pm\", \"3am\", \"Christmas_Eve\", \"3_in_the_morning\", \"1:00\", \"tuesday\", \"2:00\", \"5:30_am\", \"5:30_in_the_morning\", \"6_am\", \"3:30\", \"That_morning\", \"long_weekend\", \"4_a.m.\", \"13th\", \"5pm\", \"8pm\", \"Sometime\", \"regular_day\", \"9:00\", \"evening\", \"Wednesday_morning\", \"12:30\", \"next_morning\", \"3:00\", \"That_day\", \"6:30_am\", \"3:00\", \"3:30\", \"12:00_pm\", \"10:00\", \"10_am\", \"11:00\", \"moring\", \"10:30\", \"1:30\", \"7_a.m.\", \"9_pm\", \"eight_thirty\", \"nine_in_the_morning\", \"9:00am\", \"2:30\", \"3_o'clock\", \"friday\", \"favorite_day\", \"3:00\", \"8_pm\", \"Monday\", \"the_next_morning\", \"11am\", \"10pm\", \"nine\", \"3:30\", \"6_pm\", \"2:00\", \"Tomorrow\", \"first_morning\", \"Sunday\", \"1:00\", \"morning\", \"11:00_am\", \"eleven\", \"4:00\", \"afternoon\", \"10:00_am\", \"11_pm\", \"12:00\", \"1_a.m.\", \"three_in_the_morning\", \"school_days\", \"9:00_am\", \"mornings\", \"9:00\", \"9:00_pm\", \"2:30\", \"11:00_pm\", \"5:00\", \"7_o'clock\", \"6:00\", \"about_midnight\", \"last_week\", \"6pm\", \"10_in_the_morning\", \"8_a.m.\", \"weekday\", \"3_a.m.\", \"9:30\", \"4:30\", \"Early\", \"Christmas_Eve\", \"12pm\", \"Yesterday\", \"6:30\", \"Todays\", \"8:30\", \"Tommorow\", \"8:00_pm\", \"2:30\", \"a_half_day\", \"second_day\", \"6:00_pm\", \"the_whole_day\", \"8:30_am\", \"7_pm\", \"my_day\", \"10:30_am\", \"6:00\", \"12:30\", \"10:00\", \"dance_practice\", \"12:30\", \"following_morning\", \"durring\", \"four_in_the_morning\", \"long_nap\", \"monday\", \"One_week\", \"6:30\", \"school_time\", \"8:00\", \"four_thirty\", \"6:00_a.m.\", \"4:00\", \"4:00_am\", \"6_hours\", \"summer_holidays\", \"late_night\", \"about_11\", \"todays\", \"tomorrows\", \"12:00\", \"5.30\", \"Earlier\", \"about_5_hours\", \"6:00\", \"9:30\", \"10_pm\", \"Graduation\", \"The_next_day\", \"a_big_day\", \"Remembering\", \"7:30_am\", \"4:30\", \"cheer_practice\", \"7.30\", \"New_Years_Eve\", \"10:00\", \"11:30\", \"This_morning\", \"Christmas_vacation\", \"3am\", \"the_following_day\", \"Sunday_afternoon\", \"New_Year's\", \"One_month\", \"untill\"]\n"
     ]
    }
   ],
   "source": [
    "lexicon.create_category(\"custom_times\", [\"once_upon_a_time\", \"next_day\",\"that_evening\"], size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon.create_category(\"custom_times_3\", [\"when\", \"next_day\",\"one_time\"], size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"church\", \"temple\", \"chapel\", \"altar\", \"palace\", \"base\", \"manor\", \"castle\", \"cathedral\", \"graveyard\", \"cemetery\", \"chamber\", \"chambers\", \"gardens\", \"tower\", \"estate\", \"garden\", \"greenhouse\", \"tomb\", \"building\", \"valley\", \"Church\", \"shrine\", \"forge\", \"caravan\", \"alter\", \"city\", \"fortress\", \"keep\"]\n",
      "[\"return\", \"visit\", \"travel\", \"arrive\", \"depart\", \"leave\", \"relocate\", \"visiting\", \"accompany\", \"retire\", \"travel\", \"arriving\"]\n",
      "[\"buildings\", \"city\", \"houses\", \"other_buildings\", \"place\", \"tall_buildings\", \"huts\", \"structures\", \"cities\", \"other_houses\", \"ruins\", \"warehouses\", \"roads\", \"area\", \"vehicles\", \"skyscrapers\", \"tunnels\", \"mountains\", \"landscape\", \"areas\", \"pathways\", \"fences\", \"roofs\", \"towns\", \"building\", \"entire_place\", \"banks\", \"caves\", \"farms\", \"forests\", \"cottages\", \"countryside\", \"entire_city\", \"mansions\", \"factories\", \"tombs\", \"hills\", \"statues\", \"grid\", \"surrounding_area\", \"dome\", \"whole_city\", \"small_area\", \"whole_area\", \"alleyways\", \"cathedral\", \"homes\", \"trees\", \"plains\", \"greenery\", \"fields\", \"towers\", \"grounds\", \"residents\", \"entrances\", \"marketplace\", \"sidewalks\", \"borders\", \"places\", \"tourists\", \"perimeter\", \"gardens\", \"civilization\", \"entire_area\", \"doorways\", \"globe\", \"bridges\", \"factory\", \"terrain\", \"villages\", \"large_area\", \"few_places\", \"compound\", \"markets\", \"canyon\", \"shack\", \"farmland\", \"pillars\", \"Buildings\", \"palm_trees\", \"stone_walls\", \"pods\", \"rooftops\", \"structure\", \"alleys\", \"tower\", \"neighborhoods\", \"hillside\", \"cars\", \"cliffs\", \"columns\", \"small_village\", \"town\", \"wasteland\", \"warehouse\", \"vegetation\", \"windows\", \"white_house\", \"streets\", \"cavern\", \"open_space\", \"fortress\", \"tombstones\", \"Houses\", \"marsh\", \"whole_building\", \"hedges\", \"rubble\", \"sewers\", \"old_buildings\", \"boats\", \"turrets\", \"swamp\", \"small_houses\", \"landmarks\", \"grove\", \"farmhouse\", \"wreckage\", \"boulders\", \"tall_trees\", \"shrubbery\", \"apartments\", \"complex\", \"museum\", \"inhabitants\", \"underground\", \"enclosure\", \"domes\", \"harbor\", \"orchard\", \"ships\", \"acres\", \"wildlife\", \"underground\", \"brick_walls\", \"tents\", \"apartment_buildings\", \"jungle\", \"thick_trees\", \"many_places\", \"aircraft\", \"Trees\", \"graveyard\", \"outskirts\", \"wagons\", \"interior\", \"locals\", \"cluster\", \"plaza\", \"slopes\", \"slums\", \"city_streets\", \"walkways\", \"sights\", \"old_building\", \"dense_forest\", \"moat\", \"caravan\", \"shrubs\", \"shelters\", \"islands\", \"quarry\", \"small_building\", \"occupants\", \"trains\", \"constructed\", \"small_cabin\", \"walls\", \"mountain_range\", \"mountain\", \"valley\", \"masses\", \"corpses\", \"whole_place\", \"shacks\", \"civilisation\", \"maze\", \"different_parts\", \"different_areas\", \"rolling_hills\", \"castles\", \"many_trees\", \"torches\", \"land\", \"objects\", \"broken_windows\", \"fountains\", \"canals\", \"town_hall\", \"roof\", \"many_buildings\", \"castle\", \"wilderness\", \"entire_town\", \"caverns\", \"east\", \"large_city\", \"trucks\", \"small_shops\", \"exterior\", \"monument\", \"town_square\", \"village\", \"fenced\", \"lawns\", \"openings\", \"different_places\", \"balconies\", \"lighthouse\", \"bases\", \"neighbourhood\", \"facility\", \"small_cottage\", \"north\", \"castle_walls\", \"skyline\", \"other_areas\", \"tunnel\", \"glass_windows\", \"foothills\", \"shops\", \"planes\", \"outer_walls\", \"spaces\", \"docks\", \"woodland\", \"cottage\", \"small_island\", \"large_house\", \"routes\", \"lower_levels\", \"region\", \"boundary\", \"forest\", \"spaceship\", \"high_walls\", \"mirrors\", \"south\", \"businesses\", \"Manhattan\", \"distances\", \"glass_walls\", \"large_building\", \"other_trees\", \"neighborhood\", \"clusters\", \"coastline\", \"city_walls\", \"branching\", \"cabins\", \"planets\", \"port\", \"citadel\", \"settlement\", \"path\", \"mansion\", \"passageways\", \"debris\", \"other_building\", \"helicopters\", \"decks\", \"small_house\", \"dirt_roads\", \"large_field\", \"small_place\", \"expanse\", \"labyrinth\", \"churches\", \"graves\", \"craft\", \"footprints\", \"pines\", \"dead_bodies\", \"foliage\", \"air_vents\", \"ponds\", \"greenhouse\", \"restaurants\", \"sanctuary\", \"mainland\", \"layout\", \"gravestones\", \"bunker\", \"carriages\", \"lakes\", \"continent\", \"huge_wall\", \"abandoned_building\", \"stores\", \"caravans\", \"barns\", \"highways\", \"canopy\", \"railroad_tracks\", \"safe_zone\", \"ceilings\", \"bars\"]\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization of this is heavily required\n",
    "lexicon.create_category(\"religious_buildings\", [\"church\",\"mosque\", \"temple\"], model=\"fiction\", size = 30)\n",
    "lexicon.create_category(\"loc_verbs\", [\"arrive\", \"visit\", \"travel\", \"return\"], model = \"fiction\", size= 14)\n",
    "lexicon.create_category(\"fictional_places\", [\"place\",\"buildings\"], model =\"fiction\", size =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_story_of_the_merchant_son', 'the_aged_mother', 'the_thief_and_the_brahmins', 'the_monkey_and_the_crocodile', 'the_monkey_the_wedge']\n"
     ]
    }
   ],
   "source": [
    "story_names = []\n",
    "file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\Storynames.txt\")\n",
    "file_story_names = file.readlines()\n",
    "for name in file_story_names:\n",
    "    story_names.append(name.strip('\\n'))\n",
    "file.close()\n",
    "print(story_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_story(Storyname):\n",
    "    file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\\\\"+Storyname+'.txt')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "def annotate_story(text):\n",
    "    with CoreNLPClient(annotators = ['tokenize','ssplit'],\n",
    "        memory='5G', be_quiet=True, outputFormat = 'json', max_char_length=500000, timeout=36000000) as client:\n",
    "        annotated_story = client.annotate(text)\n",
    "    return annotated_story\n",
    "def open_and_annotate(Storyname):\n",
    "    text = open_story(Storyname)\n",
    "    annotated_story = annotate_story(text)\n",
    "    return text, annotated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_by_location_and_time(text,ann):\n",
    "    \"\"\"\n",
    "    Non-hierarchy model\n",
    "    \"\"\"\n",
    "    #This function finds sum of dictionary returned by lexicon.analyze i.e., it finds the presence of location words.\n",
    "    def sum_of_locs_dict(dictionary):\n",
    "        sum_ = 0\n",
    "        for key in dictionary.keys():\n",
    "            sum_ = sum_ + dictionary[key]\n",
    "        return sum_\n",
    "       \n",
    "    lexicon = Empath()   #Part of code used to bring Empath in\n",
    "    locations_dict = dict()     #Dictionary that holds\n",
    "    location = \"Unknown\"    #The variable place will hold latest location word.\n",
    "                            #It is initilized to \"unknown\" beacuse till now we haven't encountered any location word.\n",
    "    loaction_by_sentence = []\n",
    "    location_to_number = dict() # Convert location words to numbers for better representation\n",
    "    loc_num = 0 # Will be used to put location words as numbers in the location_to_number dict\n",
    "    total_sentences = 0\n",
    "    \n",
    "    #Take each sentence of the story one by one (ann.sentence returns individual sentences of the story as objects)\n",
    "    for i, sentence in enumerate(ann.sentence):\n",
    "        # Remove comma and fullstop beacuse lexicon.analyze cannot identify words if they are followd by a fullstop or comma.\n",
    "        # text[characterOffsetBegin:characterOffserEnd] is the actual sentence (as a string) of the sentence object returned\n",
    "        sentence_for_empath = text[sentence.characterOffsetBegin:sentence.characterOffsetEnd].replace(\", \",\" \").replace(\".\",\"\").replace(\"-\",\" \").replace(\"?\",\"\").replace(\"!\",\"\").replace(\":\",\" \")\n",
    "        #Lemmatize the words you encounter for better identification when being analysed by lexicon.analyze\n",
    "        #May be commented out because lexicon.create_category does not give good words when singular words are used\n",
    "        sentence_for_empath = lemmatize_sentence(sentence_for_empath) # Sentences are all lemmatized now\n",
    "        # Analyze the things\n",
    "        lexicon_locations_dict = lexicon.analyze(sentence_for_empath,\n",
    "                                                categories=[\"religious_buildings\", \"loc_verbs\", \"fictional_places\", \"custom_times\"])\n",
    "        \n",
    "        s = sum_of_locs_dict(lexicon_locations_dict)\n",
    "        if s>0:\n",
    "            words = sentence_for_empath.split(\" \")\n",
    "            # Find if place is same as previous\n",
    "            for word in words:\n",
    "                # If the word is a location word\n",
    "                if sum_of_locs_dict(lexicon.analyze(word,\n",
    "                                                   categories=[\"religious_buildings\", \"loc_verbs\", \"fictional_places\", \"custom_times\"]))>0:\n",
    "                    #if new location word encountered is the same as the last location word encountered\n",
    "                    if word == location:\n",
    "                        break\n",
    "                    else:\n",
    "                        location = word\n",
    "                        if location in locations_dict:\n",
    "                            location+=\"1\"\n",
    "                        locations_dict[location]=[i]\n",
    "                        location_to_number[location] = loc_num\n",
    "                        loc_num += 1\n",
    "        else: \n",
    "            if location not in locations_dict:\n",
    "                locations_dict[location] = list()\n",
    "            locations_dict[location].append(i)\n",
    "        total_sentences = i\n",
    "    return locations_dict, location_to_number, total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_event_list(locations_dict):\n",
    "    events= []\n",
    "    for location in locations_dict:\n",
    "        events.append(locations_dict[location][0])\n",
    "    events.sort()\n",
    "    events.append(total_sentences)\n",
    "    while events[0] == 0:\n",
    "        del events[0]\n",
    "    return set(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-16 01:27:12 INFO: Writing properties to tmp file: corenlp_server-9c5b13d8f1da484d.props\n",
      "2021-03-16 01:27:12 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-9c5b13d8f1da484d.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-16 01:27:16 INFO: Writing properties to tmp file: corenlp_server-3664a1ccd4db4a3d.props\n",
      "2021-03-16 01:27:16 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-3664a1ccd4db4a3d.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-16 01:27:18 INFO: Writing properties to tmp file: corenlp_server-114bc39e07f24bc2.props\n",
      "2021-03-16 01:27:18 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-114bc39e07f24bc2.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-16 01:27:19 INFO: Writing properties to tmp file: corenlp_server-66c88968f9da43b5.props\n",
      "2021-03-16 01:27:19 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-66c88968f9da43b5.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-16 01:27:21 INFO: Writing properties to tmp file: corenlp_server-6e990ac25554494b.props\n",
      "2021-03-16 01:27:21 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-6e990ac25554494b.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "my_list_of_events = []\n",
    "for i,name in enumerate(story_names):\n",
    "    text , annotated_story = open_and_annotate(name)\n",
    "    locations_dict, location_number_map, total_sentences = events_by_location_and_time(text, annotated_story)\n",
    "    my_list_of_events.append(construct_event_list(locations_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{6, 7, 8, 10, 15, 27, 30, 33, 46, 51, 62, 65},\n",
       " {1, 10, 11, 15, 17, 23, 28, 30, 54},\n",
       " {2, 8, 16, 18, 23, 25, 48},\n",
       " {9, 24, 47, 56, 60},\n",
       " {1, 2, 4, 11}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_of_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
